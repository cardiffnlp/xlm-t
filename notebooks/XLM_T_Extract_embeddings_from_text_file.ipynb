{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "XLM-T - Extract embeddings from text file",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roqXItRC92au"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook illustrates how to use `XLM-T` models for encoding a dataset from a text file into tweet embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaoDr57T74ag"
      },
      "source": [
        "# Installs and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXC3dguV3cDb"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWLw1TOn6P_u"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhakJgjlIvC0"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aP-pGTWHFH7"
      },
      "source": [
        "def preprocess(corpus):\n",
        "  outcorpus = []\n",
        "  for text in corpus:\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    new_text = \" \".join(new_text)\n",
        "    outcorpus.append(new_text)\n",
        "  return outcorpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqnM48t2MtLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724c75a4-8497-4550-c8b1-7564f336eef0"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/test_text.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-26 22:29:21--  https://raw.githubusercontent.com/cardiffnlp/xlm-t/main/data/sentiment/all/test_text.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 654172 (639K) [text/plain]\n",
            "Saving to: â€˜test_text.txtâ€™\n",
            "\n",
            "\rtest_text.txt         0%[                    ]       0  --.-KB/s               \rtest_text.txt       100%[===================>] 638.84K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-04-26 22:29:21 (35.6 MB/s) - â€˜test_text.txtâ€™ saved [654172/654172]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGWH45yrIkOH"
      },
      "source": [
        "dataset_path = './test_text.txt'\n",
        "dataset = open(dataset_path).read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTdC_qDhLO-I",
        "outputId": "21b46a79-b590-4c11-ce2a-f36f3404e213"
      },
      "source": [
        "# this is a dataset in 8 different languages\n",
        "for example in [0,870,1740,2610,3480,4350,5220,6090]:\n",
        "  print(dataset[example])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ù†ÙˆØ§Ù„ Ø§Ù„Ø²ØºØ¨ÙŠ (Ø§Ù„Ø´Ø§Ø¨ Ø®Ø§Ù„Ø¯ Ù„ÙŠØ³ Ø¹Ø§Ù„Ù…ÙŠ) Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø£ØªÙØ±Ø¬ÙŠ Ø¹Ù„Ù‰ Ù‡Ø§ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙŠØ§ Ù…Ø¨ØªØ¯Ø¦Ø© http vÃ­a @user\n",
            "Trying to have a conversation with my dad about vegetarianism is the most pointless infuriating thing ever #caveman \n",
            "Royal: le prÃ©sident n'aime pas les pauvres? \"c'est n'importe quoi\" http â€¦\n",
            "@user korrekt! Verstehe sowas nicht...\n",
            "CONGRESS na ye party kabhi bani hoti na india ka partition hota nd na hi humari country itni khokhli hoti   @ \n",
            "@user @user Ma Ferrero? il compagno Ferrero? ma il suo partito esiste ancora? allora stiamo proprio frecati !!!\n",
            "todos os meus favoritos na prova de eliminaÃ§Ã£o #MasterChefBR\n",
            "@user jajajaja dale, hacete la boluda vos jajaja igual a vos nunca se te puede tomar en serio te mando un abrazo desde PerÃº!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S6wUeuqIsVI"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8v8HPwj6P_y"
      },
      "source": [
        "CUDA = True # set to true if using GPU (Runtime -> Change runtime Type -> GPU)\n",
        "BATCH_SIZE = 32\n",
        "MODEL = \"cardiffnlp/twitter-xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "model = AutoModel.from_pretrained(MODEL)\n",
        "if CUDA:\n",
        "  model = model.to('cuda')\n",
        "_ = model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9fsx8PPInt-"
      },
      "source": [
        "## Encode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Bhdf7cGsIX"
      },
      "source": [
        "def encode(text, cuda=True):\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "  if cuda:\n",
        "    encoded_input.to('cuda')\n",
        "    output = model(**encoded_input)\n",
        "    embeddings = output[0].detach().cpu().numpy()\n",
        "  else:\n",
        "    output = model(**encoded_input)\n",
        "    embeddings = output[0].detach().numpy()\n",
        "  \n",
        "  embeddings = np.max(embeddings, axis=1)\n",
        "  #embeddings = np.mean(embeddings, axis=1) \n",
        "  return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRCMvwm7GsK3"
      },
      "source": [
        "dl = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "all_embeddings = np.zeros([len(dataset), 768])\n",
        "for idx,batch in enumerate(dl):\n",
        "  print('Batch ',idx+1,' of ',len(dl))\n",
        "  text = preprocess(batch)\n",
        "  embeddings = encode(text, cuda=CUDA)\n",
        "  a = idx*BATCH_SIZE\n",
        "  b = (idx+1)*BATCH_SIZE\n",
        "  all_embeddings[a:b,:]=embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDAlJfAsexuk"
      },
      "source": [
        "## Cosine similarity and retrieval of all embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HLO2lJRGsYb"
      },
      "source": [
        "norms = np.linalg.norm(all_embeddings, axis=-1)\n",
        "all_embeddings_unit = all_embeddings/norms[:,None]\n",
        "all_embeddings_sim = np.dot(all_embeddings_unit, all_embeddings_unit.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9tnce1siLcw"
      },
      "source": [
        "def get_most_sim(sim):\n",
        "  s = np.argsort(sim)\n",
        "  s = s[::-1] # invert sort order\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "517DcmgHiLhu"
      },
      "source": [
        "query = 1111\n",
        "a = 870  # english text from\n",
        "b = 1740 # english text to\n",
        "tmp_sim = all_embeddings_sim[a:b,query]\n",
        "tmp_data = dataset[a:b]\n",
        "s = get_most_sim(tmp_sim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHcK6Q5MiLj-",
        "outputId": "ab26d271-716b-49c0-f9d0-f1ff1a581bd0"
      },
      "source": [
        "print('QUERY: ', dataset[query])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QUERY:  This means they believe it to be a legitimate non-violent movement based on a concern for human rights in #Palestine. #queensu #ygk \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmSrUBK_brnU",
        "outputId": "5fe77766-f59b-4de5-8aec-09ae1e24006f"
      },
      "source": [
        "print(' ----- Most similar ----- ')\n",
        "too_much = 10\n",
        "for i in s:\n",
        "  print(tmp_sim[i], tmp_data[i])\n",
        "  if too_much < 0:\n",
        "    break\n",
        "  too_much-=1\n",
        "\n",
        "print(' ----- Least similar ----- ')\n",
        "too_much = 10\n",
        "for i in s[::-1]:\n",
        "  print(tmp_sim[i], tmp_data[i])\n",
        "  if too_much < 0:\n",
        "    break\n",
        "  too_much-=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ----- Most similar ----- \n",
            "0.9999999999999998 This means they believe it to be a legitimate non-violent movement based on a concern for human rights in #Palestine. #queensu #ygk \n",
            "0.964109671884958 @user aint in support with Israel nor Palestine! Hope this fire is settled soon & there's no more massacre in #Palestine either... \n",
            "0.9612606761750646 Israel deems comatose Gaza man who needs treatment in West Bank  a security threat. #Palestine  via @user \n",
            "0.9593051201529168 #latestnews 4 #newmexico #politics + #nativeamerican + #Israel + #Palestine  -  Protesting Rise Of Alt-Right At... \n",
            "0.9588319060541266 UK Govt reject criticism on Libya saying its involvement saved lives-... wishing UK to enjoy post Gadafi Libya fate. #UK #libya \n",
            "0.9583803569594294 @user Megyn, Please interview Halderman from the Univ of Michigan re:discrepancy in the results in counties with e-voting machines. \n",
            "0.9579723960580191 Saakashvili is pushing his own agenda here.The Ukrainian economy is growing, although corruption is still a problemâ€¦ \n",
            "0.9576858924401306 The decision to recount votes in Wisconsin is a joke. Leftists are still spotting-the-dummy of their loss. #TrumpTransition \n",
            "0.9575296861201772 #POTUSTrump voters are very comfortable with #TrumpTransitionTeam process because the drama reads a lot like #OldTestament:#MAGAforDummies \n",
            "0.9573203969048119 From moment he was elected Far-Rightists accused Obama of Jewphobia because he didn't conform to their politics - a baseless vicious attack. \n",
            "0.9571552708232502 Mooreder When Michael Moore picks up your cause, then wrecks you. \"He so called out the DNC! It was mooreder I tells ya!\" #UsefulNewVerbs \n",
            "0.957113374681253 @user Yes. Thank you Wikileaks for being the honest provider of facts in the 2016 election. You saved us from the TPP and Islamization \n",
            " ----- Least similar ----- \n",
            "0.8184730888874354 @user homeopathy \n",
            "0.8575587032126448 Love and Books and Valentines \n",
            "0.8580105833705889 Thank you!  @user @user @user \n",
            "0.8623854672808469 @user @user found one more. \n",
            "0.870630122026467 Match my grind ðŸ˜ \n",
            "0.8733395281608738 FUCK BOB DYLAN \n",
            "0.8773919927727969 Bob Dylan is the greatest. \n",
            "0.8820384943330573 Go Marine Le Pen!ðŸ‘‡ðŸ‘ \n",
            "0.8856072124880807 @user trump cabinet is all white \n",
            "0.8882612250493653 Pelosi should go no matter \n",
            "0.8891776545063227 @user @user I was just thinking this the other day! \n",
            "0.8902943052306831 WestWorld is even more meta than Community. \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}